#!/usr/bin/env python3
"""
OperatorQA ç¤ºä¾‹å…¥å£è„šæœ¬ï¼ˆéå‘½ä»¤è¡Œå·¥å…·ï¼‰
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

ç”¨æ³•ï¼š
  1) ä¿®æ”¹æœ¬æ–‡ä»¶é¡¶éƒ¨çš„ Example config å¸¸é‡ï¼ˆQUERY / INTERACTIVE / TOP_K / MODEL ç­‰ï¼‰
  2) ç›´æ¥è¿è¡Œï¼špython run_dfa_operator_qa.py
"""

from __future__ import annotations

import asyncio
import json
import os
import sys
from pathlib import Path
from typing import Any, Dict, List

# æ·»åŠ é¡¹ç›®è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parent.parent
sys.path.insert(0, str(PROJECT_ROOT))

from dataflow_agent.state import DFRequest, MainState
from dataflow_agent.workflow.wf_operator_qa import create_operator_qa_graph
from dataflow_agent.logger import get_logger

log = get_logger(__name__)

# ===== Example config (edit here) =====
INTERACTIVE = True
QUERY = "æˆ‘æƒ³æ¸…æ´—æ•°æ®ï¼Œåº”è¯¥ç”¨å“ªä¸ªç®—å­ï¼Ÿ"

LANGUAGE = "zh"
SESSION_ID = "demo_operator_qa"
CACHE_DIR = "dataflow_cache"
TOP_K = 5

CHAT_API_URL = os.getenv("DF_API_URL", "http://123.129.219.111:3000/v1/")
API_KEY = os.getenv("DF_API_KEY", "")
MODEL = os.getenv("DF_MODEL", "gpt-4o")

OUTPUT_JSON = "cache_local/operator_qa_result.json"  # e.g. "cache_local/operator_qa_result.json"ï¼›ç©ºå­—ç¬¦ä¸²è¡¨ç¤ºä¸è½ç›˜


# è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼ˆå¤„ç†æ¶ˆæ¯å¯¹è±¡ï¼‰
class MessageJSONEncoder(json.JSONEncoder):
    """è‡ªå®šä¹‰JSONç¼–ç å™¨ï¼Œå¤„ç†æ¶ˆæ¯å¯¹è±¡ç­‰ä¸å¯åºåˆ—åŒ–ç±»å‹"""
    def default(self, obj: Any) -> Any:
        # å¤„ç†æ¶ˆæ¯å¯¹è±¡
        if hasattr(obj, '__class__'):
            obj_class_name = obj.__class__.__name__
            # åŒ¹é…å¸¸è§çš„æ¶ˆæ¯å¯¹è±¡ç±»å‹
            if obj_class_name in ["SystemMessage", "HumanMessage", "AIMessage", "ChatMessage"]:
                return {
                    "type": obj_class_name,
                    "content": getattr(obj, "content", ""),
                    "role": getattr(obj, "role", ""),
                    "additional_kwargs": getattr(obj, "additional_kwargs", {}),
                    "metadata": getattr(obj, "metadata", {})
                }
        # å¤„ç†å…¶ä»–å¯è½¬æ¢ä¸ºå­—å…¸çš„å¯¹è±¡
        if hasattr(obj, "model_dump"):
            return obj.model_dump()
        if hasattr(obj, "__dict__"):
            return obj.__dict__
        # å…œåº•ï¼šè½¬ä¸ºå­—ç¬¦ä¸²
        return str(obj)


# è‡ªå®šä¹‰æ¶ˆæ¯å¯¹è±¡è½¬å­—å…¸ï¼ˆå•ä¸ª/åˆ—è¡¨ï¼‰
def message_to_dict(msg: Any) -> Dict[str, Any]:
    """å°†å•ä¸ªæ¶ˆæ¯å¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸"""
    if isinstance(msg, (dict, str, int, float, bool, type(None))):
        return msg
    # ä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨è½¬æ¢
    return MessageJSONEncoder().default(msg)

def messages_to_list(messages: Any) -> List[Dict[str, Any]]:
    """å°†æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸åˆ—è¡¨"""
    if not isinstance(messages, list):
        return []
    return [message_to_dict(msg) for msg in messages]


def _safe_setattr(obj, key, value):
    """å­—æ®µä¸å­˜åœ¨å°±è·³è¿‡ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬ DFRequest"""
    if hasattr(obj, key):
        setattr(obj, key, value)

def normalize_final_state(final_state_any):
    """
    å°† graph.ainvoke çš„è¿”å›ç»“æœç»Ÿä¸€è§„èŒƒä¸º dict
    å…¼å®¹ï¼š
      - dict
      - pydantic BaseModel (model_dump)
      - æ™®é€šå¯¹è±¡ (__dict__)
    """
    if isinstance(final_state_any, dict):
        return final_state_any

    if hasattr(final_state_any, "model_dump"):
        return final_state_any.model_dump()

    if hasattr(final_state_any, "__dict__"):
        return final_state_any.__dict__

    raise TypeError(f"Unsupported final_state type: {type(final_state_any)}")

async def run_single_query(state: MainState, graph, query: str) -> Dict[str, Any]:
    """
    æ‰§è¡Œå•æ¬¡æŸ¥è¯¢ï¼ˆå¤ç”¨ main() ä¸­æ„é€ çš„ state/graphï¼‰
    Args:
        state: ä¸»çŠ¶æ€ï¼ˆåŒ…å« request/messagesï¼‰
        graph: å·²ç¼–è¯‘çš„ workflow graph
        query: ç”¨æˆ·æŸ¥è¯¢
    Returns:
        æ ‡å‡†åŒ–ç»“æœ dict
    """
    # å¤ç”¨åŒä¸€ä¸ª state/graphï¼›æ¯æ¬¡åªæ›´æ–° target
    log.info(f"æ­£åœ¨å¤„ç†æŸ¥è¯¢: {query}")
    state.request.target = query

    try:
        #final_state = await graph.ainvoke(state)
        final_state_any = await graph.ainvoke(state)
        final_state_dict = normalize_final_state(final_state_any)

    except Exception as e:
        log.error(f"æ‰§è¡Œå¤±è´¥: {e}")
        return {
            "success": False,
            "error": str(e),
            "query": query,
        }

    # æå–ç»“æœ
    # agent_result = final_state.get("agent_results", {}).get("operator_qa", {})
    agent_result = final_state_dict.get("agent_results", {}).get("operator_qa", {})

    results = agent_result.get("results", {})

    # ========== ä¿®æ”¹ï¼šå¤„ç†messagesï¼Œè½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„åˆ—è¡¨ ==========
    raw_messages = final_state_dict.get("messages", [])
    serializable_messages = messages_to_list(raw_messages)

    return {
        "success": True,
        "query": query,
        "answer": results.get("answer", ""),
        "related_operators": results.get("related_operators", []),
        "code_snippet": results.get("code_snippet", ""),
        "follow_up_suggestions": results.get("follow_up_suggestions", []),
        "messages": serializable_messages,  # ä½¿ç”¨è½¬æ¢åçš„æ¶ˆæ¯åˆ—è¡¨
    }

async def interactive_mode(state: MainState, graph):
    """
    äº¤äº’æ¨¡å¼ - å¤šè½®å¯¹è¯

    é€šè¿‡å¤ç”¨åŒä¸€ä¸ª graph å’Œ stateï¼Œå®ç°çœŸæ­£çš„å¤šè½®å¯¹è¯ã€‚
    state.messages ä¼šåœ¨å¤šè½®å¯¹è¯ä¸­ç´¯ç§¯ï¼ŒLLM èƒ½çœ‹åˆ°å®Œæ•´çš„å¯¹è¯å†å²ã€‚
    """
    print("\n" + "=" * 60)
    print("  DataFlow ç®—å­é—®ç­”åŠ©æ‰‹ (äº¤äº’æ¨¡å¼)")
    print("=" * 60)
    print("\næ¬¢è¿ä½¿ç”¨ DataFlow ç®—å­é—®ç­”åŠ©æ‰‹ï¼")
    print("ä½ å¯ä»¥è¯¢é—®å…³äº DataFlow ç®—å­çš„ä»»ä½•é—®é¢˜ã€‚")
    print("\nå‘½ä»¤:")
    print("  - è¾“å…¥é—®é¢˜è¿›è¡ŒæŸ¥è¯¢")
    print("  - è¾“å…¥ 'exit' æˆ– 'quit' é€€å‡º")
    print("  - è¾“å…¥ 'clear' æ¸…é™¤å¯¹è¯å†å²")
    print("  - è¾“å…¥ 'history' æŸ¥çœ‹å¯¹è¯å†å²")
    print("-" * 60 + "\n")

    # state / graph å·²åœ¨ main() ä¸­æ„é€ ï¼Œè¿™é‡Œåªè´Ÿè´£äº¤äº’å¾ªç¯

    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            query = input("\nğŸ§‘ ä½ : ").strip()

            if not query:
                continue

            # å¤„ç†å‘½ä»¤
            if query.lower() in ["exit", "quit", "q"]:
                print("\nğŸ‘‹ å†è§ï¼")
                break

            if query.lower() == "clear":
                # æ¸…é™¤å¯¹è¯å†å²ï¼šé‡ç½® state.messages
                state.messages = []
                print("âœ… å¯¹è¯å†å²å·²æ¸…é™¤")
                continue

            if query.lower() == "history":
                if not state.messages:
                    print("ğŸ“ å¯¹è¯å†å²ä¸ºç©º")
                else:
                    print(f"\nğŸ“ å¯¹è¯å†å² ({len(state.messages)} æ¡æ¶ˆæ¯):")
                    for i, msg in enumerate(state.messages):
                        role = "ğŸ§‘ ä½ " if msg.type == "human" else "ğŸ¤– åŠ©æ‰‹" if msg.type == "ai" else f"[{msg.type}]"
                        content = msg.content[:100] + "..." if len(msg.content) > 100 else msg.content
                        print(f"  [{i+1}] {role}: {content}")
                continue

            # æ›´æ–°æŸ¥è¯¢
            state.request.target = query

            # æ‰§è¡ŒæŸ¥è¯¢ï¼ˆå¤ç”¨åŒä¸€ä¸ª stateï¼Œmessages ä¼šç´¯ç§¯ï¼‰
            print("\nâ³ æ­£åœ¨æ€è€ƒ...")
            try:
                # graph.ainvoke è¿”å›çš„æ˜¯å­—å…¸ï¼Œéœ€è¦æ›´æ–° state
                final_state_any = await graph.ainvoke(state)
                final_state_dict = normalize_final_state(final_state_any)

                # æ›´æ–° state çš„ messagesï¼ˆç”¨äºä¸‹ä¸€è½®å¯¹è¯ï¼‰
                if "messages" in final_state_dict:
                    state.messages = final_state_dict["messages"]

                # æ›´æ–° agent_results
                if "agent_results" in final_state_dict:
                    state.agent_results = final_state_dict["agent_results"]

            except Exception as e:
                log.error(f"æ‰§è¡Œå¤±è´¥: {e}")
                print(f"\nâŒ æŸ¥è¯¢å¤±è´¥: {e}")
                continue

            # æå–ç»“æœï¼ˆä»å­—å…¸ä¸­è·å–ï¼‰
            agent_result = final_state_dict.get("agent_results", {}).get("operator_qa", {})
            results = agent_result.get("results", {})

            if results:
                # æ˜¾ç¤ºå›ç­”
                answer = results.get("answer", "")
                print(f"\nğŸ¤– åŠ©æ‰‹: {answer}")

                # æ˜¾ç¤ºä¿¡æ¯æ¥æº
                source = results.get("source_explanation", "")
                if source:
                    print(f"\nğŸ“Œ ä¿¡æ¯æ¥æº: {source}")

                # æ˜¾ç¤ºç›¸å…³ç®—å­
                related_ops = results.get("related_operators", [])
                if related_ops:
                    print(f"\nğŸ“¦ ç›¸å…³ç®—å­: {', '.join(related_ops)}")

                # æ˜¾ç¤ºä»£ç ç‰‡æ®µ
                code_snippet = results.get("code_snippet", "")
                if code_snippet:
                    print(f"\nğŸ“„ ä»£ç ç‰‡æ®µ:\n{code_snippet[:500]}...")

                # æ˜¾ç¤ºåç»­å»ºè®®
                suggestions = results.get("follow_up_suggestions", [])
                if suggestions:
                    print("\nğŸ’¡ ä½ å¯èƒ½è¿˜æƒ³é—®:")
                    for suggestion in suggestions[:3]:
                        print(f"   - {suggestion}")

                # æ˜¾ç¤ºå½“å‰æ¶ˆæ¯æ•°é‡ï¼ˆè°ƒè¯•ç”¨ï¼‰
                log.debug(f"å½“å‰æ¶ˆæ¯å†å²: {len(state.messages)} æ¡")
            else:
                print(f"\nâŒ æœªè·å–åˆ°æœ‰æ•ˆç»“æœ")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å†è§ï¼")
            break
        except Exception as e:
            log.exception(f"å‘ç”Ÿé”™è¯¯: {e}")
            print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")


def format_result(result: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–è¾“å‡ºç»“æœ"""
    lines = []
    lines.append("\n" + "=" * 60)
    lines.append("  æŸ¥è¯¢ç»“æœ")
    lines.append("=" * 60)

    lines.append(f"\nğŸ“ é—®é¢˜: {result.get('query', '')}")
    lines.append(f"\nğŸ’¬ å›ç­”:\n{result.get('answer', 'æ— å›ç­”')}")

    if result.get("related_operators"):
        lines.append(f"\nğŸ“¦ ç›¸å…³ç®—å­: {', '.join(result['related_operators'])}")

    if result.get("code_snippet"):
        lines.append(f"\nğŸ“„ ä»£ç ç‰‡æ®µ:\n{result['code_snippet']}")

    if result.get("follow_up_suggestions"):
        lines.append("\nğŸ’¡ åç»­å»ºè®®:")
        for s in result["follow_up_suggestions"]:
            lines.append(f"   - {s}")

    lines.append("\n" + "=" * 60)
    return "\n".join(lines)


async def main():
    """ä¸»å‡½æ•°"""
    # ===== æ˜¾å¼æ„é€  DFRequestï¼ˆç¤ºä¾‹å…¥å£çš„æ ¸å¿ƒï¼‰=====
    req = DFRequest(
        language=LANGUAGE,
        chat_api_url=CHAT_API_URL,
        api_key=API_KEY,
        model=MODEL,
        target="",  # æ¯æ¬¡æŸ¥è¯¢å‰å†å†™å…¥
    )
    _safe_setattr(req, "chat_api_key", API_KEY)  # å…¼å®¹æ—§å­—æ®µ
    _safe_setattr(req, "top_k", TOP_K)
    _safe_setattr(req, "cache_dir", CACHE_DIR)
    _safe_setattr(req, "session_id", SESSION_ID)

    if not API_KEY:
        log.warning("DF_API_KEY æœªè®¾ç½®ï¼Œè°ƒç”¨å¯èƒ½å¤±è´¥ï¼ˆç¤ºä¾‹è„šæœ¬å¯ç»§ç»­è¿è¡Œï¼‰")

    state = MainState(request=req, messages=[])
    graph = create_operator_qa_graph().build()

    log.info(
        "OperatorQA config: model=%s url=%s session_id=%s cache_dir=%s top_k=%s",
        getattr(req, "model", ""),
        getattr(req, "chat_api_url", ""),
        getattr(req, "session_id", ""),
        getattr(req, "cache_dir", ""),
        getattr(req, "top_k", ""),
    )

    if INTERACTIVE:
        await interactive_mode(state, graph)
        return

    result = await run_single_query(state, graph, QUERY)
    
    # ä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨å†™å…¥JSON ==========
    if OUTPUT_JSON:
        Path(OUTPUT_JSON).parent.mkdir(parents=True, exist_ok=True)
        with open(OUTPUT_JSON, "w", encoding="utf-8") as f:
            # ä½¿ç”¨è‡ªå®šä¹‰ç¼–ç å™¨åºåˆ—åŒ–
            json.dump(result, f, ensure_ascii=False, indent=2, cls=MessageJSONEncoder)
        print(f"âœ… ç»“æœå·²ä¿å­˜åˆ°: {OUTPUT_JSON}")
    else:
        print(format_result(result))


if __name__ == "__main__":
    asyncio.run(main())


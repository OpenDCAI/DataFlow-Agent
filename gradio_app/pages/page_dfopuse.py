#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Gradio UI ‚Äì DataFlow Operator Pipeline Runner
"""

import json
import inspect
import os
import asyncio
from collections import defaultdict
from pathlib import Path
from typing import List, Dict, Any
from dataflow_agent.state import DFRequest, DFState
from dataflow_agent.workflow import run_workflow
from dataflow_agent.logger import get_logger
from dataflow_agent.utils import get_project_root

log = get_logger(__name__)

import gradio as gr

# -------------------- ÂáÜÂ§áÁÆóÂ≠êÂÖÉÊï∞ÊçÆ --------------------
from dataflow.utils.registry import OPERATOR_REGISTRY
import dataflow.operators                  
OPERATOR_REGISTRY._get_all()              
_ALL_OPS = OPERATOR_REGISTRY.get_obj_map()

_CAT2OPS: Dict[str, List[str]] = defaultdict(list)
for op_name, cls in _ALL_OPS.items():
    mod_parts = cls.__module__.split(".")
    if "operators" in mod_parts:
        cat_idx = mod_parts.index("operators") + 1
        category = mod_parts[cat_idx] if cat_idx < len(mod_parts) else "uncategorized"
    else:
        category = "uncategorized"
    _CAT2OPS[category].append(op_name)


# -------------------- ÂêéÁ´ØÊâßË°å --------------------
async def run_df_op_usage_pipeline(               
    matched_ops_with_params: List[Dict[str, Dict[str, Any]]],
    json_file: str,
    chat_api_url: str,
    api_key: str,
    model: str = "gpt-4o",
    language: str = "zh",
    cache_dir: str = f"{get_project_root()}/dataflow_cache",
    session_id: str = "test_session_001",
):
    req = DFRequest(
        language=language,
        model=model,
        target="ÊµãËØï pipeline ÁîüÊàêÂíåÊâßË°å",
        json_file=json_file,
        cache_dir=cache_dir,
        session_id=session_id,
        use_local_model=False,
        need_debug=False,
        chat_api_url=chat_api_url,
        api_key=api_key,
    )

    matched_ops_with_params = [
    {"op_name": list(d.keys())[0], "params": list(d.values())[0]}
    for d in matched_ops_with_params
]
    state = DFState(
        request=req,
        messages=[],
        opname_and_params=matched_ops_with_params,
    )

    log.info("ÂºÄÂßãÊâßË°å df_op_usage workflow...")
    final_state = await run_workflow("df_op_usage", state)
    log.info("df_op_usage workflow ÊâßË°åÂÆåÊàê")

    return final_state


# -------------------- Gradio È°µÈù¢ --------------------
def create_page_dfopuse():
    with gr.Blocks(title="DataFlow-Agent UI") as page:
        gr.Markdown("## üß© DataFlow Operator Selector & Pipeline Runner")

        # ========= 0. È°∂ÈÉ® ‚Äì API / Êñá‰ª∂Ë∑ØÂæÑ =========
        with gr.Row():
            chat_api_url_tb = gr.Textbox(
                label="Chat API URL",
                value="http://123.129.219.111:3000/v1/",
                scale=3,
            )
            apikey_tb = gr.Textbox(label="API Key", type="password", scale=2)
            jsonl_path_tb = gr.Textbox(
                label="ËæìÂÖ• JSONL Êñá‰ª∂Ë∑ØÂæÑ",
                placeholder="/path/to/input.jsonl",
                scale=3,
            )

        gr.Markdown("---")

        # ========= 1. ÁÆóÂ≠êÈÄâÊã© =========
        with gr.Row(equal_height=False):
            # ----- Â∑¶ÂàóÔºöÈÄâÊã© & ÊûÑÂª∫ pipeline -----
            with gr.Column(scale=4):
                cat_dd = gr.Dropdown(
                    label="ÁÆóÂ≠êÂàÜÁ±ª",
                    choices=sorted(_CAT2OPS.keys()),
                )
                op_dd = gr.Dropdown(label="ÁÆóÂ≠ê", choices=[])

                param_code = gr.Code(
                    label="run() ÂèÇÊï∞ÔºàJSON ÂèØÁºñËæëÔºâ",
                    language="json",
                    value="{}",
                    lines=12,
                )

                with gr.Row():
                    add_btn = gr.Button("‚ûï Ê∑ªÂä†ÁÆóÂ≠êÂà∞ Pipeline", variant="primary")
                    clear_btn = gr.Button("üóëÔ∏è Ê∏ÖÁ©∫ Pipeline", variant="secondary")

                pipeline_state = gr.State([])  # List[Dict[op_name -> params]]
                pipeline_json = gr.JSON(label="ÂΩìÂâç Pipeline", value=[])

                run_btn = gr.Button("üöÄ ËøêË°å Pipeline", variant="primary", size="lg")

            # ----- Âè≥ÂàóÔºöÂèÇÊï∞ËØ¥Êòé -----
            with gr.Column(scale=6):
                param_md = gr.Markdown("_ËØ∑ÈÄâÊã©‰∏Ä‰∏™ÁÆóÂ≠ê_")

        # ========= 2. ÁªìÊûúÂ±ïÁ§∫ =========
        gr.Markdown("---")
        gr.Markdown("### üìä ÊâßË°åÁªìÊûú")

        with gr.Tabs():
            with gr.Tab("ÁîüÊàêÁöÑ‰ª£Á†Å"):
                code_out = gr.Code(label="ÁîüÊàêÁöÑ Python ‰ª£Á†Å", language="python", lines=25)
            with gr.Tab("Â§ÑÁêÜÁªìÊûúÊï∞ÊçÆÔºàÂâç 100 Êù°Ôºâ"):
                result_out = gr.JSON()
            with gr.Tab("ËæìÂá∫Êñá‰ª∂Ë∑ØÂæÑ"):
                out_file_tb = gr.Textbox(interactive=False)

        # ========= 3. ‰∫§‰∫íÈÄªËæë =========
        # --- ÈÄâÂàÜÁ±ª -> Âà∑Êñ∞ÁÆóÂ≠ê ---
        cat_dd.change(
            lambda cat: gr.Dropdown(choices=sorted(_CAT2OPS.get(cat, []))),
            cat_dd,
            op_dd,
        )

        # --- ÈÄâÁÆóÂ≠ê -> Â±ïÁ§∫ÂèÇÊï∞ÈªòËÆ§ÂÄº & ËØ¥Êòé ---
        def _show_params(op_name: str):
            if not op_name:
                return "_ËØ∑ÈÄâÊã©‰∏Ä‰∏™ÁÆóÂ≠ê_", "{}"

            cls = _ALL_OPS[op_name]
            if not hasattr(cls, "run"):
                return f"‚ö†Ô∏è `{op_name}` Ê≤°ÊúâÂÆö‰πâ run() ÊñπÊ≥ï", "{}"

            sig = inspect.signature(cls.run)
            md_lines, defaults = [], {}
            md_lines.append(f"### `{op_name}.run()` ÂèÇÊï∞ËØ¥Êòé\n")
            for n, p in sig.parameters.items():
                if n == "self":
                    continue
                ann = (
                    f"`{p.annotation.__name__}`"
                    if p.annotation not in (inspect._empty, None)
                    else ""
                )
                default_val = p.default if p.default is not inspect._empty else ""
                md_lines.append(f"- **{n}** {ann}  \n  ÈªòËÆ§ÂÄºÔºö`{default_val}`")
                defaults[n] = default_val

            return "\n".join(md_lines), json.dumps(
                defaults, indent=2, ensure_ascii=False
            )

        op_dd.change(_show_params, op_dd, [param_md, param_code])

        # --- Ê∑ªÂä†ÁÆóÂ≠êÂà∞ pipeline ---
        def _add_op(op_name, param_json, pl):
            if not op_name:
                gr.Warning("‚ö†Ô∏è ËØ∑ÈÄâÊã©ÁÆóÂ≠ê")
                return pl, pl
            try:
                params = json.loads(param_json or "{}")
            except json.JSONDecodeError as e:
                gr.Warning(f"JSON Ëß£ÊûêÂ§±Ë¥•Ôºö{e}")
                return pl, pl
            pl = list(pl)  # clone
            pl.append({op_name: params})
            gr.Info(f"‚úÖ Â∑≤Ê∑ªÂä†ÁÆóÂ≠ê `{op_name}`")
            return pl, pl

        add_btn.click(
            _add_op, [op_dd, param_code, pipeline_state], [pipeline_state, pipeline_json]
        )

        # --- Ê∏ÖÁ©∫ pipeline ---
        clear_btn.click(lambda: ([], []), None, [pipeline_state, pipeline_json])

        # --- ËøêË°å pipeline ---
        async def _run_pipeline(pl, jsonl_path, chat_api_url, apikey):
            if not pl:
                gr.Warning("Pipeline ‰∏∫Á©∫ÔºåËØ∑ÂÖàÊ∑ªÂä†ÁÆóÂ≠ê")
                return "", None, ""
            if not jsonl_path:
                gr.Warning("ËØ∑ËæìÂÖ• jsonl Êñá‰ª∂Ë∑ØÂæÑ")
                return "", None, ""

            # Ë∞ÉÁî®ÂêéÁ´Ø
            try:
                final_state = await run_df_op_usage_pipeline(
                    matched_ops_with_params=pl,
                    json_file=jsonl_path,
                    chat_api_url=chat_api_url,
                    api_key=apikey,
                )
            except Exception as e:  # ÊçïËé∑ÊâÄÊúâÂºÇÂ∏∏ÔºåÈò≤Ê≠¢ UI Â¥©Ê∫É
                import traceback, io

                buf = io.StringIO()
                traceback.print_exc(file=buf)
                return f"# ÊâßË°åÂ§±Ë¥•\n\n{buf.getvalue()}", None, ""

            # 1) ‰ª£Á†ÅÊòæÁ§∫
            code_str = final_state['temp_data'].get("code", "# Êú™ÁîüÊàê code")

            # 2) Â§ÑÁêÜÁªìÊûú
            output_file = final_state['temp_data'].get("output_file",'# Êú™ÁîüÊàê output file')
            data_preview = None
            if output_file and Path(output_file).exists():
                data_preview = []
                with open(output_file, "r", encoding="utf-8") as f:
                    for i, line in enumerate(f):
                        if i >= 100:
                            break
                        try:
                            data_preview.append(json.loads(line))
                        except Exception:
                            data_preview.append({"raw_line": line.strip()})

            return code_str, data_preview, output_file or ""

        run_btn.click(
            _run_pipeline,
            inputs=[pipeline_state, jsonl_path_tb, chat_api_url_tb, apikey_tb],
            outputs=[code_out, result_out, out_file_tb],
        )

    return page

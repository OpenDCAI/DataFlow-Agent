"""
Auto-generated by pipeline_assembler
"""
from dataflow.pipeline import PipelineABC
from dataflow.utils.storage import FileStorage
from dataflow.serving import APILLMServing_request, LocalModelLLMServing_vllm

from dataflow.operators.core_text.filter.prompted_filter import PromptedFilter
from dataflow.operators.core_text.generate.prompted_generator import PromptedGenerator
from dataflow.operators.core_text.generate.text2qa_generator import Text2QAGenerator


class RecommendPipeline(PipelineABC):
    def __init__(self):
        super().__init__()
        # -------- FileStorage --------
        self.storage = FileStorage(
            first_entry_file_name="/mnt/DataFlow/lz/proj/DataFlow/dataflow/example/GeneralTextPipeline/translation.jsonl",
            cache_path="./cache_local",
            file_name_prefix="dataflow_cache_step",
            cache_type="jsonl",
        )
        # -------- LLM Serving (Remote) --------
        self.llm_serving = APILLMServing_request(
            api_url="http://123.129.219.111:3000/v1/chat/completions",
            key_name_of_api_key="DF_API_KEY",
            model_name="gpt-4o",
            max_workers=100,
        )

        self.prompted_filter = PromptedFilter(
            llm_serving=self.llm_serving,
            system_prompt="Please evaluate the quality of this data on a scale from 1 to 5.",
            min_score=1,
            max_score=5,
        )
        self.prompted_generator = PromptedGenerator(
            llm_serving=self.llm_serving,
            system_prompt="You are a helpful agent.",
            json_schema=None,
        )
        self.text2_qa_generator = Text2QAGenerator(llm_serving=self.llm_serving)

    def forward(self):
        # Run prompted filter on the raw content
        self.prompted_filter.run(
            storage=self.storage.step(),
            input_key="raw_content",
            output_key="eval",
        )
        # Generate additional content based on the raw content
        self.prompted_generator.run(
            storage=self.storage.step(),
            input_key="raw_content",
            output_key="generated_content",
        )
        # Generate QA pairs using the same raw_content column as input text
        self.text2_qa_generator.run(
            storage=self.storage.step(),
            input_key="raw_content",  # corrected from 'text' to 'raw_content'
            input_question_num=1,
            output_prompt_key="generated_prompt",
            output_quesion_key="generated_question",
            output_answer_key="generated_answer",
        )


if __name__ == "__main__":
    pipeline = RecommendPipeline()
    pipeline.compile()
    pipeline.forward()

{
  "request": {
    "language": "en",
    "chat_api_url": "http://123.129.219.111:3000/v1/",
    "api_key": "sk-h6nyfmxUx70YUMBQNwaayrmXda62L7rxvytMNshxACWVzJXe",
    "model": "gpt-4o",
    "json_file": "/mnt/DataFlow/lz/proj/DataFlow/dataflow/example/GeneralTextPipeline/translation.jsonl",
    "target": "给我随意符合逻辑的5个算子，过滤，去重！",
    "python_file_path": "/mnt/DataFlow/lz/proj/DataFlow-Agent/dataflow_agent/tmps/dXNlcm5hbWU9bGl1emhvdQ==/my_pipeline.py",
    "need_debug": false,
    "max_debug_rounds": 2,
    "use_local_model": false,
    "local_model_path": "",
    "cache_dir": "/mnt/DataFlow/lz/proj/DataFlow-Agent/cache_dir",
    "session_id": "dXNlcm5hbWU9bGl1emhvdQ=="
  },
  "messages": [
    {
      "content": "\nYou are a data processing expert. Please generate a structured JSON report according to the user's question.\nBased on the user's knowledge base data, you will recommend a suitable data processing pipeline composed of multiple processing nodes.\nYou need to analyze the user's data types and content, then recommend an appropriate pipeline accordingly.\n",
      "additional_kwargs": {},
      "response_metadata": {},
      "type": "system",
      "name": null,
      "id": "67b52d52-3923-455f-8cd4-0bb48611c2c8"
    },
    {
      "content": "\n[ROLE] You are a data governance workflow recommendation system.\nYou need to automatically select appropriate operator nodes and assemble a complete data processing pipeline based on contextual information.\n\n[INPUT]\nYou will receive the following information:\nThe requirements that the pipeline must meet:\n========\n给我随意符合逻辑的5个算子，过滤，去重！\n========\nSample data information:\n========\n[{'raw_content': 'Ablation studies demonstrate the importance of each component in the translation pipeline.'}]\n========\nThe list of available operators for each data type:\n============================\n\"CodeAutoGeneratedSampleEvaluator\":\"基于自动生成标记评估代码样本，检测文件头部的自动生成标记。\n\n评估指标：\n- CodeAutoGeneratedMarkerCount: 检测到的自动生成标记数量\n- CodeAutoGeneratedScore: 综合自动生成得分 (0-1，1表示非自动生成)\n\n输入要求：需要包含'lines'列\n\n输出参数：\n- CodeAutoGeneratedMarkerCount: 检测到的自动生成标记数量\n- CodeAutoGeneratedScore: 综合自动生成得分\"; \"CodeAutoGeneratedFilter\":\"基于CodeAutoGeneratedSampleEvaluator的得分过滤自动生成的代码文件，确保只保留人工编写的代码。\n\n评估指标：\n- 自动生成标记数量：检测文件前5行中的自动生成标记\n- 检测标记：'auto-generated', 'autogenerated', 'automatically generated'等\n- 综合自动生成得分：0-1，1表示非自动生成\n- 支持外部检测函数进行额外验证\n\n输入参数：\n- input_key: 输入字段名（需要包含'lines'列）\n- output_key: 输出标签字段名 (默认: 'auto_generated_filter_label')\n- min_score: 最小自动生成得分阈值 (默认: 1.0)\n- max_score: 最大自动生成得分阈值 (默认: 1.0)\n- is_generated_func: 可选的外部检测函数\n\n输出参数：\n- 过滤后的DataFrame，仅保留自动生成得分在指定范围内的代码样本\n- 返回包含自动生成得分标签字段名的列表\"; \"CodeDocumentQualitySampleEvaluator\":\"基于综合文档级质量指标评估代码样本，包括内容长度、重复模式、字符组成和文本熵值。\n\n评估指标：\n- CodeDocumentQualityCharCount: 字符数\n- CodeDocumentQualityWordCount: 词数\n- CodeDocumentQualityDuplicateLinesRatio: 重复行比例\n- CodeDocumentQualityDuplicateNgramRatio: n-gram重复比例\n- CodeDocumentQualityCurlyBracketRatio: 花括号比例\n- CodeDocumentQualityAllCapsRatio: 全大写单词比例\n- CodeDocumentQualityEntropy: 单字符熵值\n- CodeDocumentQualityScore: 综合文档质量得分 (0-1，1表示通过所有质量检查)\n\n输入要求：需要包含'text'、'filename'、'language'列\n\n输出参数：\n- 各种质量指标的数值\n- CodeDocumentQualityScore: 综合文档质量得分\"; \"CodeDocumentQualityFilter\":\"基于CodeDocumentQualitySampleEvaluator的得分应用综合文档级质量过滤规则，移除低质量代码和文本样本。\n\n评估指标：\n- 内容长度：字符数、词数、行数范围检查\n- 重复模式：重复行比例、2-10gram重复比例\n- 字符组成：花括号比例、全大写单词比例\n- 文本熵值：单字符熵值检查\n- 综合文档质量得分：0-1，1表示通过所有质量检查\n\n输入参数：\n- input_key: 输入字段名（需要包含'text'、'filename'、'language'列）\n- output_key: 输出标签字段名 (默认: 'doc_quality_filter_label')\n- min_score: 最小文档质量得分阈值 (默认: 1.0)\n- max_score: 最大文档质量得分阈值 (默认: 1.0)\n- thresholds: 可选的阈值字典，用于覆盖默认阈值\n\n输出参数：\n- 过滤后的DataFrame，仅保留文档质量得分在指定范围内的样本\n- 返回包含文档质量得分标签字段名的列表\"; \"CodeEncodedDataSampleEvaluator\":\"基于编码数据模式评估代码样本，检测Base64、十六进制和Unicode转义序列。\n\n评估指标：\n- CodeEncodedDataBase64Ratio: Base64编码数据比例\n- CodeEncodedDataHexRatio: 十六进制数据比例\n- CodeEncodedDataUnicodeRatio: Unicode转义序列比例\n- CodeEncodedDataScore: 综合编码数据得分 (0-1，1表示通过编码数据检查)\n\n输入要求：需要包含'text'列\n\n输出参数：\n- CodeEncodedDataBase64Ratio: Base64编码数据比例\n- CodeEncodedDataHexRatio: 十六进制数据比例\n- CodeEncodedDataUnicodeRatio: Unicode转义序列比例\n- CodeEncodedDataScore: 综合编码数据得分\"; \"CodeEncodedDataFilter\":\"基于CodeEncodedDataSampleEvaluator的得分过滤代码样本，移除二进制内容和自动生成代码。\n\n评估指标：\n- Base64编码数据比例：检测连续64+字符的Base64字符串\n- 十六进制数据比例：检测8+个连续的十六进制对\n- Unicode转义序列比例：检测8+个连续的\\uXXXX序列\n- 综合编码数据得分：0-1，1表示通过检查\n\n输入参数：\n- input_key: 输入字段名（需要包含'text'列）\n- output_key: 输出标签字段名 (默认: 'encoded_data_filter_label')\n- min_score: 最小编码数据得分阈值 (默认: 1.0)\n- max_score: 最大编码数据得分阈值 (默认: 1.0)\n\n输出参数：\n- 过滤后的DataFrame，仅保留编码数据得分在指定范围内的代码样本\n- 返回包含编码数据得分标签字段名的列表\"; \"CodeFileTypeContentFilter\":\"基于文件类型和内容特征直接过滤代码样本，针对不同文件格式应用特定规则。\n\n过滤规则：\n- Text/JSON/YAML/Graphviz文件：行数 > 512 行\n- HTML文件：可见文本长度 < 100字符 或 可见文本比例 < 20%\n- Text文件：文件名不符合文档规范（非readme/notes/todo等）\n\n输入参数：\n- input_key: 输入字段名（需要包含'filetype'、'filename'、'line_count'等列）\n- output_key: 输出标签字段名 (默认: 'file_type_content_filter_label')\n\n输出参数：\n- 过滤后的DataFrame，仅保留符合文件类型规则的样本\n- 返回包含输出标签字段名的列表\"; \"CodeLengthSampleEvaluator\":\"基于代码长度特征评估代码样本，分析总行数、平均行长和最大行长。\n\n评估指标：\n- CodeLengthTotalLines: 总行数\n- CodeLengthAvgLineLength: 平均行长\n- CodeLengthMaxLineLength: 最大行长\n- CodeLengthScore: 综合长度得分 (0-1，1表示通过所有长度检查)\n\n输入要求：需要包含'lines'和'language'列\n\n输出参数：\n- CodeLengthTotalLines: 总行数\n- CodeLengthAvgLineLength: 平均行长\n- CodeLengthMaxLineLength: 最大行长\n- CodeLengthScore: 综合长度得分\"; \"CodeLengthSampleFilter\":\"基于CodeLengthSampleEvaluator的得分过滤代码样本，移除超大文件和格式不良的代码。\n\n评估指标：\n- 总行数：检查是否超过100,000行\n- 平均行长：普通语言>100字符，特殊语言>100,000字符\n- 最大行长：普通语言>1,000字符\n\n输入参数：\n- input_key: 输入字段名（需要包含'lines'和'language'列）\n- output_key: 输出标签字段名 (默认: 'length_filter_label')\n- min_score: 最小长度得分阈值 (默认: 1.0)\n- max_score: 最大长度得分阈值 (默认: 1.0)\n\n输出参数：\n- 过滤后的DataFrame，仅保留长度得分在指定范围内的代码样本\n- 返回包含长度得分标签字段名的列表\"; \"CodeQualitySampleEvaluator\":\"该算子用于评估生成的代码片段与其源指令的匹配质量，并输出分数和反馈。\n\n输入参数：\n- input_instruction_key: 包含人类指令的字段名 (默认: 'generated_instruction')\n- input_code_key: 包含生成代码的字段名 (默认: 'generated_code')\n输出参数：\n- output_score_key: 用于存储质量分数的字段名 (默认: 'quality_score')\n- output_feedback_key: 用于存储质量反馈的字段名 (默认: 'quality_feedback')\n\"; \"CodeQualityScoreFilter\":\"基于LLM生成的代码质量分数过滤代码样本，评估正确性、完整性、清晰度、最佳实践和效率。\n\n评估维度：\n- 正确性：代码语法和逻辑是否正确\n- 完整性：代码是否完整实现功能\n- 清晰度：代码是否清晰易懂\n- 最佳实践：是否遵循编程最佳实践\n- 效率：代码执行效率如何\n\n输入参数：\n- input_key: 输入字段名（需要包含指令和代码列）\n- output_key: 输出标签字段名 (默认: 'quality_score')\n- min_score: 最小质量分数阈值 (默认: 7)\n- max_score: 最大质量分数阈值 (默认: 10)\n\n输出参数：\n- 过滤后的DataFrame，仅保留质量分数在指定范围内的代码样本\n- 返回包含质量分数标签字段名的列表\"; \"CodeGenericScoreFilter\":\"基于数值分数列直接过滤数据集，提供灵活的阈值比较方法。\n\n比较方法：\n- greater_equal: 分数 >= 阈值\n- greater: 分数 > 阈值\n- less_equal: 分数 <= 阈值\n- less: 分数 < 阈值\n- equal: 分数 = 阈值\n\n输入参数：\n- input_key: 包含分数的字段名\n- output_key: 输出标签字段名 (默认: 'generic_score_filter_label')\n- score_threshold: 分数阈值 (默认: 8)\n- filter_method: 比较方法 (默认: 'greater_equal')\n\n输出参数：\n- 过滤后的DataFrame，仅保留符合分数条件的样本\n- 返回包含输出标签字段名的列表\"; \"CodeTextCompositionSampleEvaluator\":\"基于字符组成评估代码样本，分析字母字符和字母数字字符的比例。\n\n评估指标：\n- CodeTextCompositionAlphaRatio: 字母字符比例\n- CodeTextCompositionAlnumRatio: 字母数字字符比例\n- CodeTextCompositionScore: 综合字符组成得分 (0-1，1表示通过字符组成检查)\n\n输入要求：需要包含'text'和'language'列\n\n输出参数：\n- CodeTextCompositionAlphaRatio: 字母字符比例\n- CodeTextCompositionAlnumRatio: 字母数字字符比例\n- CodeTextCompositionScore: 综合字符组成得分\"; \"CodeTextCompositionFilter\":\"基于CodeTextCompositionSampleEvaluator的得分过滤代码样本，移除二进制文件、加密内容和不可读文本。\n\n评估指标：\n- 字母字符比例：普通语言需要>=25%\n- 字母数字字符比例：汇编语言需要>=25%\n- 综合字符组成得分：0-1，1表示通过检查\n\n输入参数：\n- input_key: 输入字段名（需要包含'text'和'language'列）\n- output_key: 输出标签字段名 (默认: 'text_composition_filter_label')\n- min_score: 最小字符组成得分阈值 (默认: 1.0)\n- max_score: 最大字符组成得分阈值 (默认: 1.0)\n\n输出参数：\n- 过滤后的DataFrame，仅保留字符组成得分在指定范围内的代码样本\n- 返回包含字符组成得分标签字段名的列表\"; \"CodeCodeToInstructionGenerator\":\"该算子用于分析代码片段并反向生成可能产生该代码的人类指令。\n\n输入参数：\n- input_key: 包含原始代码片段的字段名 (默认: 'code')\n输出参数：\n- output_key: 用于存储生成指令的字段名 (默认: 'generated_instruction')\n\"; \"CodeInstructionToCodeGenerator\":\"该算子根据给定的人类指令生成相应的代码片段。\n\n输入参数：\n- input_key: 包含人类指令的字段名 (默认: 'instruction')\n输出参数：\n- output_key: 用于存储生成代码的字段名 (默认: 'generated_code')\n\"; \"CodeSandboxSampleEvaluator\":\"该算子在一个安全的沙箱环境中执行代码片段以验证其正确性。\n\n输入参数：\n- input_code_key: 包含待执行代码的字段名 (默认: 'generated_code')\n输出参数：\n- output_status_key: 用于存储执行状态 ('PASS' 或 'FAIL') 的字段名 (默认: 'sandbox_status')\n- output_log_key: 用于存储执行日志或错误信息的字段名 (默认: 'sandbox_log')\n\"\n============================\n\n[key rules]\n1. Follow Execution Order:\n  Data generation must occur before data extraction\n  Data extraction must occur before data validation\n  Correct order: Filter → Generate → Extract → Validate\n  Incorrect order: Filter → Extract → Generate ❌\n2 .Validate Data Availability:\n\n  Check sample data to confirm which fields already exist\n  If an operator requires field \"X\" but it's not present in the sample data, ensure a preceding operator creates it\n\n[Common Error Patterns to Avoid]\n❌ Incorrect Example: [\"FilterData\", \"ExtractAnswer\", \"GenerateAnswer\"]\nProblem: Attempting to extract the answer before it is generated\n\n✅ Correct Example: [\"FilterData\", \"GenerateAnswer\", \"ExtractAnswer\"]\nReason: Generate first, then extract\n\n❌ Incorrect Example: [\"ValidateAnswer\", \"GenerateAnswer\"]\nProblem: Validating an answer that does not exist yet\n\n✅ Correct Example: [\"GenerateAnswer\", \"ExtractAnswer\", \"ValidateAnswer\"]\nReason: Complete data flow\n\n\n[OUTPUT RULES]\n1. Please select suitable operator nodes for each type and return them in the following JSON format:\n{\n  \"ops\": [\"OperatorA\", \"OperatorB\", \"OperatorC\"],\n  \"reason\": \"State your reasoning here. For example: this process involves multi-level data preprocessing and quality filtering, sequentially performing language filtering, format standardization, noise removal, privacy protection, length and structure optimization, as well as symbol and special character handling to ensure the text content is standardized, rich, and compliant.\"\n}\n2 Only the names of the operators are needed.\n3. Please verify whether the selected operators and their order fully meet the requirements specified in 给我随意符合逻辑的5个算子，过滤，去重！.\n[Question]\nBased on the above rules, what pipeline should be recommended???\n",
      "additional_kwargs": {},
      "response_metadata": {},
      "type": "human",
      "name": null,
      "id": "dd5cd49b-3afc-4754-a5bb-b8cb82cb1d2f",
      "example": false
    },
    {
      "content": "```json\n{\n  \"ops\": [\n    \"CodeDocumentQualitySampleEvaluator\",\n    \"CodeDocumentQualityFilter\",\n    \"CodeLengthSampleEvaluator\",\n    \"CodeLengthSampleFilter\",\n    \"CodeTextCompositionSampleEvaluator\"\n  ],\n  \"reason\": \"This pipeline involves a multi-level data preprocessing and quality filtering process. It starts with evaluating the document quality to ensure the content meets certain standards, followed by filtering based on these quality scores. Next, it evaluates the code length to identify any anomalies in line length or file size, followed by filtering based on these length scores. Finally, it evaluates the text composition to ensure the content is readable and not binary or encrypted. This sequence ensures the data is filtered and deduplicated effectively, meeting the requirements of logical filtering and deduplication.\"\n}\n```",
      "additional_kwargs": {
        "refusal": null
      },
      "response_metadata": {
        "token_usage": {
          "completion_tokens": 164,
          "prompt_tokens": 3416,
          "total_tokens": 3580,
          "completion_tokens_details": {
            "accepted_prediction_tokens": 0,
            "audio_tokens": 0,
            "reasoning_tokens": 0,
            "rejected_prediction_tokens": 0
          },
          "prompt_tokens_details": {
            "audio_tokens": 0,
            "cached_tokens": 0
          }
        },
        "model_name": "gpt-4o-2024-08-06",
        "system_fingerprint": "fp_4a331a0222",
        "id": "chatcmpl-CUwoBd6d7GV8V3FCNKOrsPS4vL4jk",
        "service_tier": null,
        "finish_reason": "stop",
        "logprobs": null
      },
      "type": "ai",
      "name": null,
      "id": "run--be41bcea-45fb-4b4e-aede-32256aeb4709-0",
      "example": false,
      "tool_calls": [],
      "invalid_tool_calls": [],
      "usage_metadata": {
        "input_tokens": 3416,
        "output_tokens": 164,
        "total_tokens": 3580,
        "input_token_details": {
          "audio": 0,
          "cache_read": 0
        },
        "output_token_details": {
          "audio": 0,
          "reasoning": 0
        }
      }
    }
  ],
  "agent_results": {
    "classifier": {
      "pre_tool_results": {
        "sample": [
          {
            "raw_content": "The code and datasets are publicly available to facilitate reproducibility and further research."
          },
          {
            "raw_content": "The model was trained using a combination of supervised and unsupervised learning techniques."
          }
        ],
        "categories": [
          "agentic_rag",
          "chemistry",
          "code",
          "conversations",
          "core_speech",
          "core_text",
          "core_vision",
          "db",
          "general_text",
          "knowledge_cleaning",
          "rare",
          "reasoning",
          "text2sql",
          "text_pt",
          "text_sft"
        ]
      },
      "post_tools": [],
      "results": {
        "category": "code"
      }
    },
    "recommender": {
      "pre_tool_results": {
        "sample": [
          {
            "raw_content": "Ablation studies demonstrate the importance of each component in the translation pipeline."
          }
        ],
        "target": "给我随意符合逻辑的5个算子，过滤，去重！",
        "operator": "\"CodeAutoGeneratedSampleEvaluator\":\"基于自动生成标记评估代码样本，检测文件头部的自动生成标记。\n\n评估指标：\n- CodeAutoGeneratedMarkerCount: 检测到的自动生成标记数量\n- CodeAutoGeneratedScore: 综合自动生成得分 (0-1，1表示非自动生成)\n\n输入要求：需要包含'lines'列\n\n输出参数：\n- CodeAutoGeneratedMarkerCount: 检测到的自动生成标记数量\n- CodeAutoGeneratedScore: 综合自动生成得分\"; \"CodeAutoGeneratedFilter\":\"基于CodeAutoGeneratedSampleEvaluator的得分过滤自动生成的代码文件，确保只保留人工编写的代码。\n\n评估指标：\n- 自动生成标记数量：检测文件前5行中的自动生成标记\n- 检测标记：'auto-generated', 'autogenerated', 'automatically generated'等\n- 综合自动生成得分：0-1，1表示非自动生成\n- 支持外部检测函数进行额外验证\n\n输入参数：\n- input_key: 输入字段名（需要包含'lines'列）\n- output_key: 输出标签字段名 (默认: 'auto_generated_filter_label')\n- min_score: 最小自动生成得分阈值 (默认: 1.0)\n- max_score: 最大自动生成得分阈值 (默认: 1.0)\n- is_generated_func: 可选的外部检测函数\n\n输出参数：\n- 过滤后的DataFrame，仅保留自动生成得分在指定范围内的代码样本\n- 返回包含自动生成得分标签字段名的列表\"; \"CodeDocumentQualitySampleEvaluator\":\"基于综合文档级质量指标评估代码样本，包括内容长度、重复模式、字符组成和文本熵值。\n\n评估指标：\n- CodeDocumentQualityCharCount: 字符数\n- CodeDocumentQualityWordCount: 词数\n- CodeDocumentQualityDuplicateLinesRatio: 重复行比例\n- CodeDocumentQualityDuplicateNgramRatio: n-gram重复比例\n- CodeDocumentQualityCurlyBracketRatio: 花括号比例\n- CodeDocumentQualityAllCapsRatio: 全大写单词比例\n- CodeDocumentQualityEntropy: 单字符熵值\n- CodeDocumentQualityScore: 综合文档质量得分 (0-1，1表示通过所有质量检查)\n\n输入要求：需要包含'text'、'filename'、'language'列\n\n输出参数：\n- 各种质量指标的数值\n- CodeDocumentQualityScore: 综合文档质量得分\"; \"CodeDocumentQualityFilter\":\"基于CodeDocumentQualitySampleEvaluator的得分应用综合文档级质量过滤规则，移除低质量代码和文本样本。\n\n评估指标：\n- 内容长度：字符数、词数、行数范围检查\n- 重复模式：重复行比例、2-10gram重复比例\n- 字符组成：花括号比例、全大写单词比例\n- 文本熵值：单字符熵值检查\n- 综合文档质量得分：0-1，1表示通过所有质量检查\n\n输入参数：\n- input_key: 输入字段名（需要包含'text'、'filename'、'language'列）\n- output_key: 输出标签字段名 (默认: 'doc_quality_filter_label')\n- min_score: 最小文档质量得分阈值 (默认: 1.0)\n- max_score: 最大文档质量得分阈值 (默认: 1.0)\n- thresholds: 可选的阈值字典，用于覆盖默认阈值\n\n输出参数：\n- 过滤后的DataFrame，仅保留文档质量得分在指定范围内的样本\n- 返回包含文档质量得分标签字段名的列表\"; \"CodeEncodedDataSampleEvaluator\":\"基于编码数据模式评估代码样本，检测Base64、十六进制和Unicode转义序列。\n\n评估指标：\n- CodeEncodedDataBase64Ratio: Base64编码数据比例\n- CodeEncodedDataHexRatio: 十六进制数据比例\n- CodeEncodedDataUnicodeRatio: Unicode转义序列比例\n- CodeEncodedDataScore: 综合编码数据得分 (0-1，1表示通过编码数据检查)\n\n输入要求：需要包含'text'列\n\n输出参数：\n- CodeEncodedDataBase64Ratio: Base64编码数据比例\n- CodeEncodedDataHexRatio: 十六进制数据比例\n- CodeEncodedDataUnicodeRatio: Unicode转义序列比例\n- CodeEncodedDataScore: 综合编码数据得分\"; \"CodeEncodedDataFilter\":\"基于CodeEncodedDataSampleEvaluator的得分过滤代码样本，移除二进制内容和自动生成代码。\n\n评估指标：\n- Base64编码数据比例：检测连续64+字符的Base64字符串\n- 十六进制数据比例：检测8+个连续的十六进制对\n- Unicode转义序列比例：检测8+个连续的\\uXXXX序列\n- 综合编码数据得分：0-1，1表示通过检查\n\n输入参数：\n- input_key: 输入字段名（需要包含'text'列）\n- output_key: 输出标签字段名 (默认: 'encoded_data_filter_label')\n- min_score: 最小编码数据得分阈值 (默认: 1.0)\n- max_score: 最大编码数据得分阈值 (默认: 1.0)\n\n输出参数：\n- 过滤后的DataFrame，仅保留编码数据得分在指定范围内的代码样本\n- 返回包含编码数据得分标签字段名的列表\"; \"CodeFileTypeContentFilter\":\"基于文件类型和内容特征直接过滤代码样本，针对不同文件格式应用特定规则。\n\n过滤规则：\n- Text/JSON/YAML/Graphviz文件：行数 > 512 行\n- HTML文件：可见文本长度 < 100字符 或 可见文本比例 < 20%\n- Text文件：文件名不符合文档规范（非readme/notes/todo等）\n\n输入参数：\n- input_key: 输入字段名（需要包含'filetype'、'filename'、'line_count'等列）\n- output_key: 输出标签字段名 (默认: 'file_type_content_filter_label')\n\n输出参数：\n- 过滤后的DataFrame，仅保留符合文件类型规则的样本\n- 返回包含输出标签字段名的列表\"; \"CodeLengthSampleEvaluator\":\"基于代码长度特征评估代码样本，分析总行数、平均行长和最大行长。\n\n评估指标：\n- CodeLengthTotalLines: 总行数\n- CodeLengthAvgLineLength: 平均行长\n- CodeLengthMaxLineLength: 最大行长\n- CodeLengthScore: 综合长度得分 (0-1，1表示通过所有长度检查)\n\n输入要求：需要包含'lines'和'language'列\n\n输出参数：\n- CodeLengthTotalLines: 总行数\n- CodeLengthAvgLineLength: 平均行长\n- CodeLengthMaxLineLength: 最大行长\n- CodeLengthScore: 综合长度得分\"; \"CodeLengthSampleFilter\":\"基于CodeLengthSampleEvaluator的得分过滤代码样本，移除超大文件和格式不良的代码。\n\n评估指标：\n- 总行数：检查是否超过100,000行\n- 平均行长：普通语言>100字符，特殊语言>100,000字符\n- 最大行长：普通语言>1,000字符\n\n输入参数：\n- input_key: 输入字段名（需要包含'lines'和'language'列）\n- output_key: 输出标签字段名 (默认: 'length_filter_label')\n- min_score: 最小长度得分阈值 (默认: 1.0)\n- max_score: 最大长度得分阈值 (默认: 1.0)\n\n输出参数：\n- 过滤后的DataFrame，仅保留长度得分在指定范围内的代码样本\n- 返回包含长度得分标签字段名的列表\"; \"CodeQualitySampleEvaluator\":\"该算子用于评估生成的代码片段与其源指令的匹配质量，并输出分数和反馈。\n\n输入参数：\n- input_instruction_key: 包含人类指令的字段名 (默认: 'generated_instruction')\n- input_code_key: 包含生成代码的字段名 (默认: 'generated_code')\n输出参数：\n- output_score_key: 用于存储质量分数的字段名 (默认: 'quality_score')\n- output_feedback_key: 用于存储质量反馈的字段名 (默认: 'quality_feedback')\n\"; \"CodeQualityScoreFilter\":\"基于LLM生成的代码质量分数过滤代码样本，评估正确性、完整性、清晰度、最佳实践和效率。\n\n评估维度：\n- 正确性：代码语法和逻辑是否正确\n- 完整性：代码是否完整实现功能\n- 清晰度：代码是否清晰易懂\n- 最佳实践：是否遵循编程最佳实践\n- 效率：代码执行效率如何\n\n输入参数：\n- input_key: 输入字段名（需要包含指令和代码列）\n- output_key: 输出标签字段名 (默认: 'quality_score')\n- min_score: 最小质量分数阈值 (默认: 7)\n- max_score: 最大质量分数阈值 (默认: 10)\n\n输出参数：\n- 过滤后的DataFrame，仅保留质量分数在指定范围内的代码样本\n- 返回包含质量分数标签字段名的列表\"; \"CodeGenericScoreFilter\":\"基于数值分数列直接过滤数据集，提供灵活的阈值比较方法。\n\n比较方法：\n- greater_equal: 分数 >= 阈值\n- greater: 分数 > 阈值\n- less_equal: 分数 <= 阈值\n- less: 分数 < 阈值\n- equal: 分数 = 阈值\n\n输入参数：\n- input_key: 包含分数的字段名\n- output_key: 输出标签字段名 (默认: 'generic_score_filter_label')\n- score_threshold: 分数阈值 (默认: 8)\n- filter_method: 比较方法 (默认: 'greater_equal')\n\n输出参数：\n- 过滤后的DataFrame，仅保留符合分数条件的样本\n- 返回包含输出标签字段名的列表\"; \"CodeTextCompositionSampleEvaluator\":\"基于字符组成评估代码样本，分析字母字符和字母数字字符的比例。\n\n评估指标：\n- CodeTextCompositionAlphaRatio: 字母字符比例\n- CodeTextCompositionAlnumRatio: 字母数字字符比例\n- CodeTextCompositionScore: 综合字符组成得分 (0-1，1表示通过字符组成检查)\n\n输入要求：需要包含'text'和'language'列\n\n输出参数：\n- CodeTextCompositionAlphaRatio: 字母字符比例\n- CodeTextCompositionAlnumRatio: 字母数字字符比例\n- CodeTextCompositionScore: 综合字符组成得分\"; \"CodeTextCompositionFilter\":\"基于CodeTextCompositionSampleEvaluator的得分过滤代码样本，移除二进制文件、加密内容和不可读文本。\n\n评估指标：\n- 字母字符比例：普通语言需要>=25%\n- 字母数字字符比例：汇编语言需要>=25%\n- 综合字符组成得分：0-1，1表示通过检查\n\n输入参数：\n- input_key: 输入字段名（需要包含'text'和'language'列）\n- output_key: 输出标签字段名 (默认: 'text_composition_filter_label')\n- min_score: 最小字符组成得分阈值 (默认: 1.0)\n- max_score: 最大字符组成得分阈值 (默认: 1.0)\n\n输出参数：\n- 过滤后的DataFrame，仅保留字符组成得分在指定范围内的代码样本\n- 返回包含字符组成得分标签字段名的列表\"; \"CodeCodeToInstructionGenerator\":\"该算子用于分析代码片段并反向生成可能产生该代码的人类指令。\n\n输入参数：\n- input_key: 包含原始代码片段的字段名 (默认: 'code')\n输出参数：\n- output_key: 用于存储生成指令的字段名 (默认: 'generated_instruction')\n\"; \"CodeInstructionToCodeGenerator\":\"该算子根据给定的人类指令生成相应的代码片段。\n\n输入参数：\n- input_key: 包含人类指令的字段名 (默认: 'instruction')\n输出参数：\n- output_key: 用于存储生成代码的字段名 (默认: 'generated_code')\n\"; \"CodeSandboxSampleEvaluator\":\"该算子在一个安全的沙箱环境中执行代码片段以验证其正确性。\n\n输入参数：\n- input_code_key: 包含待执行代码的字段名 (默认: 'generated_code')\n输出参数：\n- output_status_key: 用于存储执行状态 ('PASS' 或 'FAIL') 的字段名 (默认: 'sandbox_status')\n- output_log_key: 用于存储执行日志或错误信息的字段名 (默认: 'sandbox_log')\n\""
      },
      "post_tools": [
        "combine_pipeline"
      ],
      "results": {
        "ops": [
          "CodeDocumentQualitySampleEvaluator",
          "CodeDocumentQualityFilter",
          "CodeLengthSampleEvaluator",
          "CodeLengthSampleFilter",
          "CodeTextCompositionSampleEvaluator"
        ],
        "reason": "This pipeline involves a multi-level data preprocessing and quality filtering process. It starts with evaluating the document quality to ensure the content meets certain standards, followed by filtering based on these quality scores. Next, it evaluates the code length to identify any anomalies in line length or file size, followed by filtering based on these length scores. Finally, it evaluates the text composition to ensure the content is readable and not binary or encrypted. This sequence ensures the data is filtered and deduplicated effectively, meeting the requirements of logical filtering and deduplication."
      }
    },
    "pipeline_builder": {
      "pre_tool_results": {
        "recommendation": []
      },
      "post_tools": [],
      "results": {
        "success": null,
        "skipped": true,
        "file_path": "/mnt/DataFlow/lz/proj/DataFlow-Agent/dataflow_agent/tmps/dXNlcm5hbWU9bGl1emhvdQ==/my_pipeline.py"
      }
    },
    "exporter": {
      "pre_tool_results": {
        "nodes_info": [
          {
            "id": "node1",
            "name": "CodeDocumentQualitySampleEvaluator",
            "type": "eval",
            "config": {
              "init": {
                "thresholds": null
              },
              "run": {
                "storage": "self.storage.step()",
                "input_key": null
              }
            }
          },
          {
            "id": "node2",
            "name": "CodeDocumentQualityFilter",
            "type": "filter",
            "config": {
              "init": {
                "min_score": 1.0,
                "max_score": 1.0,
                "thresholds": null
              },
              "run": {
                "storage": "self.storage.step()",
                "input_key": null,
                "output_key": "doc_quality_filter_label"
              }
            }
          },
          {
            "id": "node3",
            "name": "CodeLengthSampleEvaluator",
            "type": "eval",
            "config": {
              "init": {},
              "run": {
                "storage": "self.storage.step()",
                "input_key": null
              }
            }
          },
          {
            "id": "node4",
            "name": "CodeLengthSampleFilter",
            "type": "filter",
            "config": {
              "init": {
                "min_score": 1.0,
                "max_score": 1.0
              },
              "run": {
                "storage": "self.storage.step()",
                "input_key": null,
                "output_key": "length_filter_label"
              }
            }
          },
          {
            "id": "node5",
            "name": "CodeTextCompositionSampleEvaluator",
            "type": "eval",
            "config": {
              "init": {},
              "run": {
                "storage": "self.storage.step()",
                "input_key": null
              }
            }
          }
        ]
      },
      "post_tools": [],
      "results": {
        "nodes": [
          {
            "id": "node1",
            "name": "CodeDocumentQualitySampleEvaluator",
            "type": "eval",
            "config": {
              "init": {
                "thresholds": null
              },
              "run": {
                "storage": "self.storage.step()",
                "input_key": "raw_content"
              }
            }
          },
          {
            "id": "node2",
            "name": "CodeDocumentQualityFilter",
            "type": "filter",
            "config": {
              "init": {
                "min_score": 1.0,
                "max_score": 1.0,
                "thresholds": null
              },
              "run": {
                "storage": "self.storage.step()",
                "input_key": "raw_content",
                "output_key": "step1"
              }
            }
          },
          {
            "id": "node3",
            "name": "CodeLengthSampleEvaluator",
            "type": "eval",
            "config": {
              "init": {},
              "run": {
                "storage": "self.storage.step()",
                "input_key": "step1"
              }
            }
          },
          {
            "id": "node4",
            "name": "CodeLengthSampleFilter",
            "type": "filter",
            "config": {
              "init": {
                "min_score": 1.0,
                "max_score": 1.0
              },
              "run": {
                "storage": "self.storage.step()",
                "input_key": "step1",
                "output_key": "step2"
              }
            }
          },
          {
            "id": "node5",
            "name": "CodeTextCompositionSampleEvaluator",
            "type": "eval",
            "config": {
              "init": {},
              "run": {
                "storage": "self.storage.step()",
                "input_key": "step2"
              }
            }
          }
        ]
      }
    }
  },
  "category": {
    "category": "code"
  },
  "recommendation": [
    "CodeDocumentQualitySampleEvaluator",
    "CodeDocumentQualityFilter",
    "CodeLengthSampleEvaluator",
    "CodeLengthSampleFilter",
    "CodeTextCompositionSampleEvaluator"
  ],
  "temp_data": {
    "round": 0,
    "pre_tool_results": {
      "sample": [
        {
          "raw_content": "Ablation studies demonstrate the importance of each component in the translation pipeline."
        }
      ],
      "target": "给我随意符合逻辑的5个算子，过滤，去重！",
      "operator": "\"CodeAutoGeneratedSampleEvaluator\":\"基于自动生成标记评估代码样本，检测文件头部的自动生成标记。\n\n评估指标：\n- CodeAutoGeneratedMarkerCount: 检测到的自动生成标记数量\n- CodeAutoGeneratedScore: 综合自动生成得分 (0-1，1表示非自动生成)\n\n输入要求：需要包含'lines'列\n\n输出参数：\n- CodeAutoGeneratedMarkerCount: 检测到的自动生成标记数量\n- CodeAutoGeneratedScore: 综合自动生成得分\"; \"CodeAutoGeneratedFilter\":\"基于CodeAutoGeneratedSampleEvaluator的得分过滤自动生成的代码文件，确保只保留人工编写的代码。\n\n评估指标：\n- 自动生成标记数量：检测文件前5行中的自动生成标记\n- 检测标记：'auto-generated', 'autogenerated', 'automatically generated'等\n- 综合自动生成得分：0-1，1表示非自动生成\n- 支持外部检测函数进行额外验证\n\n输入参数：\n- input_key: 输入字段名（需要包含'lines'列）\n- output_key: 输出标签字段名 (默认: 'auto_generated_filter_label')\n- min_score: 最小自动生成得分阈值 (默认: 1.0)\n- max_score: 最大自动生成得分阈值 (默认: 1.0)\n- is_generated_func: 可选的外部检测函数\n\n输出参数：\n- 过滤后的DataFrame，仅保留自动生成得分在指定范围内的代码样本\n- 返回包含自动生成得分标签字段名的列表\"; \"CodeDocumentQualitySampleEvaluator\":\"基于综合文档级质量指标评估代码样本，包括内容长度、重复模式、字符组成和文本熵值。\n\n评估指标：\n- CodeDocumentQualityCharCount: 字符数\n- CodeDocumentQualityWordCount: 词数\n- CodeDocumentQualityDuplicateLinesRatio: 重复行比例\n- CodeDocumentQualityDuplicateNgramRatio: n-gram重复比例\n- CodeDocumentQualityCurlyBracketRatio: 花括号比例\n- CodeDocumentQualityAllCapsRatio: 全大写单词比例\n- CodeDocumentQualityEntropy: 单字符熵值\n- CodeDocumentQualityScore: 综合文档质量得分 (0-1，1表示通过所有质量检查)\n\n输入要求：需要包含'text'、'filename'、'language'列\n\n输出参数：\n- 各种质量指标的数值\n- CodeDocumentQualityScore: 综合文档质量得分\"; \"CodeDocumentQualityFilter\":\"基于CodeDocumentQualitySampleEvaluator的得分应用综合文档级质量过滤规则，移除低质量代码和文本样本。\n\n评估指标：\n- 内容长度：字符数、词数、行数范围检查\n- 重复模式：重复行比例、2-10gram重复比例\n- 字符组成：花括号比例、全大写单词比例\n- 文本熵值：单字符熵值检查\n- 综合文档质量得分：0-1，1表示通过所有质量检查\n\n输入参数：\n- input_key: 输入字段名（需要包含'text'、'filename'、'language'列）\n- output_key: 输出标签字段名 (默认: 'doc_quality_filter_label')\n- min_score: 最小文档质量得分阈值 (默认: 1.0)\n- max_score: 最大文档质量得分阈值 (默认: 1.0)\n- thresholds: 可选的阈值字典，用于覆盖默认阈值\n\n输出参数：\n- 过滤后的DataFrame，仅保留文档质量得分在指定范围内的样本\n- 返回包含文档质量得分标签字段名的列表\"; \"CodeEncodedDataSampleEvaluator\":\"基于编码数据模式评估代码样本，检测Base64、十六进制和Unicode转义序列。\n\n评估指标：\n- CodeEncodedDataBase64Ratio: Base64编码数据比例\n- CodeEncodedDataHexRatio: 十六进制数据比例\n- CodeEncodedDataUnicodeRatio: Unicode转义序列比例\n- CodeEncodedDataScore: 综合编码数据得分 (0-1，1表示通过编码数据检查)\n\n输入要求：需要包含'text'列\n\n输出参数：\n- CodeEncodedDataBase64Ratio: Base64编码数据比例\n- CodeEncodedDataHexRatio: 十六进制数据比例\n- CodeEncodedDataUnicodeRatio: Unicode转义序列比例\n- CodeEncodedDataScore: 综合编码数据得分\"; \"CodeEncodedDataFilter\":\"基于CodeEncodedDataSampleEvaluator的得分过滤代码样本，移除二进制内容和自动生成代码。\n\n评估指标：\n- Base64编码数据比例：检测连续64+字符的Base64字符串\n- 十六进制数据比例：检测8+个连续的十六进制对\n- Unicode转义序列比例：检测8+个连续的\\uXXXX序列\n- 综合编码数据得分：0-1，1表示通过检查\n\n输入参数：\n- input_key: 输入字段名（需要包含'text'列）\n- output_key: 输出标签字段名 (默认: 'encoded_data_filter_label')\n- min_score: 最小编码数据得分阈值 (默认: 1.0)\n- max_score: 最大编码数据得分阈值 (默认: 1.0)\n\n输出参数：\n- 过滤后的DataFrame，仅保留编码数据得分在指定范围内的代码样本\n- 返回包含编码数据得分标签字段名的列表\"; \"CodeFileTypeContentFilter\":\"基于文件类型和内容特征直接过滤代码样本，针对不同文件格式应用特定规则。\n\n过滤规则：\n- Text/JSON/YAML/Graphviz文件：行数 > 512 行\n- HTML文件：可见文本长度 < 100字符 或 可见文本比例 < 20%\n- Text文件：文件名不符合文档规范（非readme/notes/todo等）\n\n输入参数：\n- input_key: 输入字段名（需要包含'filetype'、'filename'、'line_count'等列）\n- output_key: 输出标签字段名 (默认: 'file_type_content_filter_label')\n\n输出参数：\n- 过滤后的DataFrame，仅保留符合文件类型规则的样本\n- 返回包含输出标签字段名的列表\"; \"CodeLengthSampleEvaluator\":\"基于代码长度特征评估代码样本，分析总行数、平均行长和最大行长。\n\n评估指标：\n- CodeLengthTotalLines: 总行数\n- CodeLengthAvgLineLength: 平均行长\n- CodeLengthMaxLineLength: 最大行长\n- CodeLengthScore: 综合长度得分 (0-1，1表示通过所有长度检查)\n\n输入要求：需要包含'lines'和'language'列\n\n输出参数：\n- CodeLengthTotalLines: 总行数\n- CodeLengthAvgLineLength: 平均行长\n- CodeLengthMaxLineLength: 最大行长\n- CodeLengthScore: 综合长度得分\"; \"CodeLengthSampleFilter\":\"基于CodeLengthSampleEvaluator的得分过滤代码样本，移除超大文件和格式不良的代码。\n\n评估指标：\n- 总行数：检查是否超过100,000行\n- 平均行长：普通语言>100字符，特殊语言>100,000字符\n- 最大行长：普通语言>1,000字符\n\n输入参数：\n- input_key: 输入字段名（需要包含'lines'和'language'列）\n- output_key: 输出标签字段名 (默认: 'length_filter_label')\n- min_score: 最小长度得分阈值 (默认: 1.0)\n- max_score: 最大长度得分阈值 (默认: 1.0)\n\n输出参数：\n- 过滤后的DataFrame，仅保留长度得分在指定范围内的代码样本\n- 返回包含长度得分标签字段名的列表\"; \"CodeQualitySampleEvaluator\":\"该算子用于评估生成的代码片段与其源指令的匹配质量，并输出分数和反馈。\n\n输入参数：\n- input_instruction_key: 包含人类指令的字段名 (默认: 'generated_instruction')\n- input_code_key: 包含生成代码的字段名 (默认: 'generated_code')\n输出参数：\n- output_score_key: 用于存储质量分数的字段名 (默认: 'quality_score')\n- output_feedback_key: 用于存储质量反馈的字段名 (默认: 'quality_feedback')\n\"; \"CodeQualityScoreFilter\":\"基于LLM生成的代码质量分数过滤代码样本，评估正确性、完整性、清晰度、最佳实践和效率。\n\n评估维度：\n- 正确性：代码语法和逻辑是否正确\n- 完整性：代码是否完整实现功能\n- 清晰度：代码是否清晰易懂\n- 最佳实践：是否遵循编程最佳实践\n- 效率：代码执行效率如何\n\n输入参数：\n- input_key: 输入字段名（需要包含指令和代码列）\n- output_key: 输出标签字段名 (默认: 'quality_score')\n- min_score: 最小质量分数阈值 (默认: 7)\n- max_score: 最大质量分数阈值 (默认: 10)\n\n输出参数：\n- 过滤后的DataFrame，仅保留质量分数在指定范围内的代码样本\n- 返回包含质量分数标签字段名的列表\"; \"CodeGenericScoreFilter\":\"基于数值分数列直接过滤数据集，提供灵活的阈值比较方法。\n\n比较方法：\n- greater_equal: 分数 >= 阈值\n- greater: 分数 > 阈值\n- less_equal: 分数 <= 阈值\n- less: 分数 < 阈值\n- equal: 分数 = 阈值\n\n输入参数：\n- input_key: 包含分数的字段名\n- output_key: 输出标签字段名 (默认: 'generic_score_filter_label')\n- score_threshold: 分数阈值 (默认: 8)\n- filter_method: 比较方法 (默认: 'greater_equal')\n\n输出参数：\n- 过滤后的DataFrame，仅保留符合分数条件的样本\n- 返回包含输出标签字段名的列表\"; \"CodeTextCompositionSampleEvaluator\":\"基于字符组成评估代码样本，分析字母字符和字母数字字符的比例。\n\n评估指标：\n- CodeTextCompositionAlphaRatio: 字母字符比例\n- CodeTextCompositionAlnumRatio: 字母数字字符比例\n- CodeTextCompositionScore: 综合字符组成得分 (0-1，1表示通过字符组成检查)\n\n输入要求：需要包含'text'和'language'列\n\n输出参数：\n- CodeTextCompositionAlphaRatio: 字母字符比例\n- CodeTextCompositionAlnumRatio: 字母数字字符比例\n- CodeTextCompositionScore: 综合字符组成得分\"; \"CodeTextCompositionFilter\":\"基于CodeTextCompositionSampleEvaluator的得分过滤代码样本，移除二进制文件、加密内容和不可读文本。\n\n评估指标：\n- 字母字符比例：普通语言需要>=25%\n- 字母数字字符比例：汇编语言需要>=25%\n- 综合字符组成得分：0-1，1表示通过检查\n\n输入参数：\n- input_key: 输入字段名（需要包含'text'和'language'列）\n- output_key: 输出标签字段名 (默认: 'text_composition_filter_label')\n- min_score: 最小字符组成得分阈值 (默认: 1.0)\n- max_score: 最大字符组成得分阈值 (默认: 1.0)\n\n输出参数：\n- 过滤后的DataFrame，仅保留字符组成得分在指定范围内的代码样本\n- 返回包含字符组成得分标签字段名的列表\"; \"CodeCodeToInstructionGenerator\":\"该算子用于分析代码片段并反向生成可能产生该代码的人类指令。\n\n输入参数：\n- input_key: 包含原始代码片段的字段名 (默认: 'code')\n输出参数：\n- output_key: 用于存储生成指令的字段名 (默认: 'generated_instruction')\n\"; \"CodeInstructionToCodeGenerator\":\"该算子根据给定的人类指令生成相应的代码片段。\n\n输入参数：\n- input_key: 包含人类指令的字段名 (默认: 'instruction')\n输出参数：\n- output_key: 用于存储生成代码的字段名 (默认: 'generated_code')\n\"; \"CodeSandboxSampleEvaluator\":\"该算子在一个安全的沙箱环境中执行代码片段以验证其正确性。\n\n输入参数：\n- input_code_key: 包含待执行代码的字段名 (默认: 'generated_code')\n输出参数：\n- output_status_key: 用于存储执行状态 ('PASS' 或 'FAIL') 的字段名 (默认: 'sandbox_status')\n- output_log_key: 用于存储执行日志或错误信息的字段名 (默认: 'sandbox_log')\n\""
    },
    "recommender_instance": {
      "tool_manager": {
        "role_pre_tools": {
          "classifier": {
            "sample": {},
            "categories": {}
          },
          "recommender": {
            "sample": {},
            "target": {},
            "operator": {}
          },
          "exporter": {
            "nodes_info": {}
          }
        },
        "role_post_tools": {
          "recommender": [
            {
              "name": "combine_pipeline",
              "description": "Combine pipeline post tool for recommender",
              "args_schema": "{'__module__': 'dataflow_agent.workflow.wf_pipeline_recommend_extract_json', '__annotations__': {'oplist': 'list'}, 'model_config': {}, '__class_vars__': set(), '__private_attributes__': {}, '__weakref__': <attribute '__weakref__' of 'GetOpInput' objects>, '__doc__': None, '__abstractmethods__': frozenset(), '_abc_impl': <_abc._abc_data object at 0x7fcf8c023100>, '__pydantic_custom_init__': False, '__pydantic_post_init__': None, '__pydantic_setattr_handlers__': {}, '__pydantic_decorators__': DecoratorInfos(validators={}, field_validators={}, root_validators={}, field_serializers={}, model_serializers={}, model_validators={}, computed_fields={}), '__pydantic_generic_metadata__': {'origin': None, 'args': (), 'parameters': ()}, '__pydantic_complete__': True, '__pydantic_parent_namespace__': {'builder': <pydantic._internal._model_construction._PydanticWeakRef object at 0x7fcf802058d0>, 'cls_get_sample': <pydantic._internal._model_construction._PydanticWeakRef object at 0x7fcf80205900>, 'cls_get_categories': <pydantic._internal._model_construction._PydanticWeakRef object at 0x7fcf80205930>, 'rec_get_sample': <pydantic._internal._model_construction._PydanticWeakRef object at 0x7fcf80205990>, 'rec_get_target': <pydantic._internal._model_construction._PydanticWeakRef object at 0x7fcf802059c0>, 'rec_get_operator': <pydantic._internal._model_construction._PydanticWeakRef object at 0x7fcf80205b40>}, '__pydantic_fields__': {'oplist': FieldInfo(annotation=list, required=True, description=\"list['xxx']的算子列表\")}, '__pydantic_computed_fields__': {}, '__pydantic_core_schema__': {'type': 'model', 'cls': <class 'dataflow_agent.workflow.wf_pipeline_recommend_extract_json.create_pipeline_graph.<locals>.GetOpInput'>, 'schema': {'type': 'model-fields', 'fields': {'oplist': {'type': 'model-field', 'schema': {'type': 'list', 'items_schema': {'type': 'any'}}, 'metadata': {'pydantic_js_updates': {'description': \"list['xxx']的算子列表\"}}}}, 'model_name': 'GetOpInput', 'computed_fields': []}, 'custom_init': False, 'root_model': False, 'config': {'title': 'GetOpInput'}, 'ref': 'dataflow_agent.workflow.wf_pipeline_recommend_extract_json.create_pipeline_graph.<locals>.GetOpInput:93987065639328', 'metadata': {'pydantic_js_functions': [<bound method BaseModel.__get_pydantic_json_schema__ of <class 'dataflow_agent.workflow.wf_pipeline_recommend_extract_json.create_pipeline_graph.<locals>.GetOpInput'>>]}}, '__pydantic_validator__': SchemaValidator(title=\"GetOpInput\", validator=Model(\n    ModelValidator {\n        revalidate: Never,\n        validator: ModelFields(\n            ModelFieldsValidator {\n                fields: [\n                    Field {\n                        name: \"oplist\",\n                        lookup_key_collection: LookupKeyCollection {\n                            by_name: Simple(\n                                LookupPath {\n                                    first_item: PathItemString {\n                                        key: \"oplist\",\n                                        py_key: Py(\n                                            0x00007fcf80211cb0,\n                                        ),\n                                    },\n                                    rest: [],\n                                },\n                            ),\n                            by_alias: None,\n                            by_alias_then_name: None,\n                        },\n                        name_py: Py(\n                            0x00007fcf80a14130,\n                        ),\n                        validator: List(\n                            ListValidator {\n                                strict: false,\n                                item_validator: None,\n                                min_length: None,\n                                max_length: None,\n                                name: OnceLock(\n                                    <uninit>,\n                                ),\n                                fail_fast: false,\n                            },\n                        ),\n                        frozen: false,\n                    },\n                ],\n                model_name: \"GetOpInput\",\n                extra_behavior: Ignore,\n                extras_validator: None,\n                extras_keys_validator: None,\n                strict: false,\n                from_attributes: false,\n                loc_by_alias: true,\n                validate_by_alias: None,\n                validate_by_name: None,\n            },\n        ),\n        class: Py(\n            0x0000557b11a931a0,\n        ),\n        generic_origin: None,\n        post_init: None,\n        frozen: false,\n        custom_init: false,\n        root_model: false,\n        undefined: Py(\n            0x00007fcf8d79b460,\n        ),\n        name: \"GetOpInput\",\n    },\n), definitions=[], cache_strings=True), '__pydantic_serializer__': SchemaSerializer(serializer=Model(\n    ModelSerializer {\n        class: Py(\n            0x0000557b11a931a0,\n        ),\n        serializer: Fields(\n            GeneralFieldsSerializer {\n                fields: {\n                    \"oplist\": SerField {\n                        key_py: Py(\n                            0x00007fcf80a14130,\n                        ),\n                        alias: None,\n                        alias_py: None,\n                        serializer: Some(\n                            List(\n                                ListSerializer {\n                                    item_serializer: Any(\n                                        AnySerializer,\n                                    ),\n                                    filter: SchemaFilter {\n                                        include: None,\n                                        exclude: None,\n                                    },\n                                    name: \"list[any]\",\n                                },\n                            ),\n                        ),\n                        required: true,\n                        serialize_by_alias: None,\n                        serialization_exclude_if: None,\n                    },\n                },\n                computed_fields: Some(\n                    ComputedFields(\n                        [],\n                    ),\n                ),\n                mode: SimpleDict,\n                extra_serializer: None,\n                filter: SchemaFilter {\n                    include: None,\n                    exclude: None,\n                },\n                required_fields: 1,\n            },\n        ),\n        has_extra: false,\n        root_model: false,\n        name: \"GetOpInput\",\n    },\n), definitions=[]), '__signature__': <pydantic._internal._utils.LazyClassAttribute object at 0x7fcf80205f90>}",
              "return_direct": false,
              "verbose": false,
              "callbacks": null,
              "callback_manager": null,
              "tags": null,
              "metadata": null,
              "handle_tool_error": false,
              "handle_validation_error": false,
              "response_format": "content",
              "func": {},
              "coroutine": null
            }
          ]
        },
        "global_pre_tools": {},
        "global_post_tools": []
      },
      "model_name": null,
      "temperature": 0.0,
      "max_tokens": 4096,
      "tool_mode": "auto",
      "react_mode": false,
      "react_max_retries": 3
    },
    "debug_sample_file": "/tmp/translation_sample_10.jsonl",
    "origin_file_path": "/mnt/DataFlow/lz/proj/DataFlow/dataflow/example/GeneralTextPipeline/translation.jsonl",
    "pipeline_code": "\"\"\"\nAuto-generated by pipeline_assembler\n\"\"\"\nfrom dataflow.pipeline import PipelineABC\nfrom dataflow.utils.storage import FileStorage\nfrom dataflow.serving import APILLMServing_request, LocalModelLLMServing_vllm\n\nfrom dataflow.operators.code import CodeDocumentQualityFilter, CodeDocumentQualitySampleEvaluator, CodeLengthSampleEvaluator, CodeLengthSampleFilter, CodeTextCompositionSampleEvaluator\n\n\n\nclass RecommendPipeline(PipelineABC):\n    def __init__(self):\n        super().__init__()\n        # -------- FileStorage --------\n        self.storage = FileStorage(\n            first_entry_file_name=\"/tmp/translation_sample_10.jsonl\",\n            cache_path=\"/mnt/DataFlow/lz/proj/DataFlow-Agent/cache_dir\",\n            file_name_prefix=\"dataflow_cache_step\",\n            cache_type=\"jsonl\",\n        )\n        # -------- LLM Serving (Remote) --------\n        self.llm_serving = APILLMServing_request(\n            api_url=\"http://123.129.219.111:3000/v1/chat/completions\",\n            key_name_of_api_key=\"DF_API_KEY\",\n            model_name=\"gpt-4o\",\n            max_workers=100,\n        )\n\n        self.code_document_quality_sample_evaluator = CodeDocumentQualitySampleEvaluator(thresholds=None)\n        self.code_document_quality_filter = CodeDocumentQualityFilter(min_score=1.0, max_score=1.0, thresholds=None)\n        self.code_length_sample_evaluator = CodeLengthSampleEvaluator()\n        self.code_length_sample_filter = CodeLengthSampleFilter(min_score=1.0, max_score=1.0)\n        self.code_text_composition_sample_evaluator = CodeTextCompositionSampleEvaluator()\n\n    def forward(self):\n        self.code_document_quality_sample_evaluator.run(\n            storage=self.storage.step(), input_key=None\n        )\n        self.code_document_quality_filter.run(\n            storage=self.storage.step(), input_key=None, output_key='doc_quality_filter_label'\n        )\n        self.code_length_sample_evaluator.run(\n            storage=self.storage.step(), input_key=None\n        )\n        self.code_length_sample_filter.run(\n            storage=self.storage.step(), input_key=None, output_key='length_filter_label'\n        )\n        self.code_text_composition_sample_evaluator.run(\n            storage=self.storage.step(), input_key=None\n        )\n\nif __name__ == \"__main__\":\n    pipeline = RecommendPipeline()\n    pipeline.compile()\n    pipeline.forward()\n",
    "structure_code": {
      "nodes": [
        {
          "id": "node1",
          "name": "CodeDocumentQualitySampleEvaluator",
          "type": "eval",
          "config": {
            "init": {
              "thresholds": null
            },
            "run": {
              "storage": "self.storage.step()",
              "input_key": null
            }
          }
        },
        {
          "id": "node2",
          "name": "CodeDocumentQualityFilter",
          "type": "filter",
          "config": {
            "init": {
              "min_score": 1.0,
              "max_score": 1.0,
              "thresholds": null
            },
            "run": {
              "storage": "self.storage.step()",
              "input_key": null,
              "output_key": "doc_quality_filter_label"
            }
          }
        },
        {
          "id": "node3",
          "name": "CodeLengthSampleEvaluator",
          "type": "eval",
          "config": {
            "init": {},
            "run": {
              "storage": "self.storage.step()",
              "input_key": null
            }
          }
        },
        {
          "id": "node4",
          "name": "CodeLengthSampleFilter",
          "type": "filter",
          "config": {
            "init": {
              "min_score": 1.0,
              "max_score": 1.0
            },
            "run": {
              "storage": "self.storage.step()",
              "input_key": null,
              "output_key": "length_filter_label"
            }
          }
        },
        {
          "id": "node5",
          "name": "CodeTextCompositionSampleEvaluator",
          "type": "eval",
          "config": {
            "init": {},
            "run": {
              "storage": "self.storage.step()",
              "input_key": null
            }
          }
        }
      ],
      "edges": []
    }
  },
  "matched_ops": [],
  "debug_mode": true,
  "pipeline_structure_code": {
    "nodes": [
      {
        "id": "node1",
        "name": "CodeDocumentQualitySampleEvaluator",
        "type": "eval",
        "config": {
          "init": {
            "thresholds": null
          },
          "run": {
            "storage": "self.storage.step()",
            "input_key": null
          }
        }
      },
      {
        "id": "node2",
        "name": "CodeDocumentQualityFilter",
        "type": "filter",
        "config": {
          "init": {
            "min_score": 1.0,
            "max_score": 1.0,
            "thresholds": null
          },
          "run": {
            "storage": "self.storage.step()",
            "input_key": null,
            "output_key": "doc_quality_filter_label"
          }
        }
      },
      {
        "id": "node3",
        "name": "CodeLengthSampleEvaluator",
        "type": "eval",
        "config": {
          "init": {},
          "run": {
            "storage": "self.storage.step()",
            "input_key": null
          }
        }
      },
      {
        "id": "node4",
        "name": "CodeLengthSampleFilter",
        "type": "filter",
        "config": {
          "init": {
            "min_score": 1.0,
            "max_score": 1.0
          },
          "run": {
            "storage": "self.storage.step()",
            "input_key": null,
            "output_key": "length_filter_label"
          }
        }
      },
      {
        "id": "node5",
        "name": "CodeTextCompositionSampleEvaluator",
        "type": "eval",
        "config": {
          "init": {},
          "run": {
            "storage": "self.storage.step()",
            "input_key": null
          }
        }
      }
    ],
    "edges": []
  },
  "execution_result": {
    "success": null,
    "skipped": true,
    "file_path": "/mnt/DataFlow/lz/proj/DataFlow-Agent/dataflow_agent/tmps/dXNlcm5hbWU9bGl1emhvdQ==/my_pipeline.py"
  },
  "code_debug_result": {}
}